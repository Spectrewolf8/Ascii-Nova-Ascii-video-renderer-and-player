{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1G9_qq-bB-ZCXe1L5gWb4fVPKgVpDwaDy",
      "authorship_tag": "ABX9TyMQ1vZIzJ3go/Qv9sih3HeC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spectrewolf8/Ascii-Nova-Ascii-video-renderer-and-player/blob/main/shaham_com_1_fruits_classifier_v2_backend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experimental**"
      ],
      "metadata": {
        "id": "nqAklidY8hXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow opencv-python matplotlib huggingface_hub"
      ],
      "metadata": {
        "id": "cYMCpbFL3CVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -r /content/drive/MyDrive/#shaham_com_1_fruits_classifier_v2-backend_storage/requirements.txt"
      ],
      "metadata": {
        "id": "A5hGiMFwEeOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports and Constants\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2"
      ],
      "metadata": {
        "id": "41a9HpI45Gnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "FRUIT_TYPES = ['Apple', 'Banana', 'Guava', 'Lime', 'Orange', 'Pomegranate']\n",
        "QUALITY_TYPES = ['Good', 'Bad']"
      ],
      "metadata": {
        "id": "6UGVcv3K5XzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "#logging into Hugging Face\n",
        "!huggingface-cli login --token $hf_token"
      ],
      "metadata": {
        "id": "q8pCC1hQ34zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEjacK7Wve6H"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define your model repository and file name\n",
        "repo_name = \"spectrewolf8/MobileNetv3_fruit_quality_classifier\"\n",
        "filename = \"MobileNetv3_fruit_quality_classifier.h5\"  # Update this to the actual model file name\n",
        "\n",
        "# Define the directory where you want to save the downloaded model\n",
        "download_dir = \"/kaggle/working/spectrewolf8/cache/\"\n",
        "\n",
        "# Download the model file from Hugging Face Hub to the specified directory\n",
        "local_model_path = hf_hub_download(repo_id=repo_name, filename=filename, cache_dir=download_dir)\n",
        "\n",
        "# !rm - rf /kaggle/working/spectrewolf8/cache/models--spectrewolf8--aerial-image-road-segmentation-xp\n",
        "\n",
        "# Load the model with custom objects\n",
        "model = tf.keras.models.load_model(local_model_path)\n",
        "\n",
        "\n",
        "# Check the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gradcam(model, image, layer_name='Conv1', target_size=(IMG_SIZE, IMG_SIZE)):\n",
        "    # Build the grad model - flatten the outputs list\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        inputs=model.inputs,\n",
        "        outputs=[model.get_layer(layer_name).output] + model.outputs  # Flatten the output list\n",
        "    )\n",
        "\n",
        "    # Add a gradient tape to monitor the computation of gradients\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass: Get the layer's output and the model's output\n",
        "        conv_outputs, fruit_type_output, quality_output = grad_model(image, training=False)\n",
        "\n",
        "        # Combine losses for both outputs\n",
        "        loss = tf.reduce_mean(fruit_type_output) + tf.reduce_mean(quality_output)\n",
        "\n",
        "    # Calculate the gradients of the combined loss w.r.t. conv layer outputs\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    # Pool gradients across the spatial dimensions (average them out)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Process the convolution outputs\n",
        "    conv_outputs = conv_outputs[0]\n",
        "\n",
        "    # Generate the Grad-CAM heatmap\n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "\n",
        "    # Resize the heatmap to the target size (200x200)\n",
        "    heatmap = cv2.resize(heatmap.numpy(), target_size, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    return heatmap"
      ],
      "metadata": {
        "id": "k6teM9IU5EWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def explain_prediction(model, image_path):\n",
        "#     # Load and preprocess the image\n",
        "#     img = tf.keras.preprocessing.image.load_img(\n",
        "#         image_path, target_size=(IMG_SIZE, IMG_SIZE)\n",
        "#     )\n",
        "#     img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "#     img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "#     # Make predictions\n",
        "#     fruit_pred, quality_pred = model.predict(img_array)\n",
        "\n",
        "#     # Generate Grad-CAM heatmap\n",
        "#     heatmap = generate_gradcam(model, img_array)\n",
        "\n",
        "#     # Plot the original image, heatmap, and heatmap only\n",
        "#     plt.figure(figsize=(15, 5))\n",
        "\n",
        "#     plt.subplot(1, 3, 1)\n",
        "#     plt.imshow(img)\n",
        "#     plt.title('Original Image')\n",
        "\n",
        "#     plt.subplot(1, 3, 2)\n",
        "#     plt.imshow(img)\n",
        "#     plt.imshow(heatmap, alpha=0.6, cmap='jet')\n",
        "#     plt.title('GradCAM Heatmap')\n",
        "\n",
        "#     plt.subplot(1, 3, 3)\n",
        "#     plt.imshow(heatmap, cmap='jet')\n",
        "#     plt.title('Heatmap Only')\n",
        "\n",
        "#     plt.show()\n",
        "\n",
        "#     # Get predictions and their confidence\n",
        "#     predicted_fruit = FRUIT_TYPES[np.argmax(fruit_pred)]\n",
        "#     fruit_confidence = np.max(fruit_pred)\n",
        "\n",
        "#     predicted_quality = QUALITY_TYPES[np.argmax(quality_pred)]\n",
        "#     quality_confidence = np.max(quality_pred)\n",
        "\n",
        "#     # Create explanatory text\n",
        "#     explanation = (\n",
        "#         f\"Prediction for the image:\\n\"\n",
        "#         f\"- Predicted Fruit: {predicted_fruit} (Confidence: {fruit_confidence:.2f})\\n\"\n",
        "#         f\"- Predicted Quality: {predicted_quality} (Confidence: {quality_confidence:.2f})\\n\\n\"\n",
        "#         f\"Insights:\\n\"\n",
        "#         f\"- The model is highly confident in the fruit prediction if the confidence is above 0.7.\\n\"\n",
        "#         f\"- Quality prediction confidence helps in understanding the ripeness and edibility of the fruit. \\n\"\n",
        "#         f\"- The Grad-CAM heatmap indicates the areas of the image that were most influential in making the predictions.\"\n",
        "#     )\n",
        "\n",
        "#     return {\n",
        "#         'fruit_type': predicted_fruit,\n",
        "#         'fruit_confidence': fruit_confidence,\n",
        "#         'quality': predicted_quality,\n",
        "#         'quality_confidence': quality_confidence,\n",
        "#         'explanation': explanation\n",
        "#     }\n",
        "\n",
        "\n",
        "# def explain_prediction(model, image_path):\n",
        "#     # Load and preprocess the image\n",
        "#     img = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "#     img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "#     img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "#     # Make predictions\n",
        "#     fruit_pred, quality_pred = model.predict(img_array)\n",
        "\n",
        "#     # Generate Grad-CAM heatmap\n",
        "#     heatmap = generate_gradcam(model, img_array)  # Assuming you have the `generate_gradcam` function\n",
        "\n",
        "#     # Save the original image, heatmap, and Grad-CAM overlay images\n",
        "#     result_dir = 'static/results'\n",
        "#     os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "#     original_image_path = os.path.join(result_dir, 'original_image.jpg')\n",
        "#     heatmap_path = os.path.join(result_dir, 'heatmap.jpg')\n",
        "#     overlay_path = os.path.join(result_dir, 'overlay_image.jpg')\n",
        "\n",
        "#     # Save the original image\n",
        "#     plt.imsave(original_image_path, img)\n",
        "\n",
        "#     # Save the heatmap-only image\n",
        "#     plt.imsave(heatmap_path, heatmap, cmap='jet')\n",
        "\n",
        "#     # Save the overlay (original image + heatmap)\n",
        "#     plt.figure(figsize=(15, 5))\n",
        "#     plt.imshow(img)\n",
        "#     plt.imshow(heatmap, alpha=0.6, cmap='jet')\n",
        "#     plt.axis('off')\n",
        "#     plt.savefig(overlay_path)\n",
        "#     plt.close()\n",
        "\n",
        "#     # Get predictions and their confidence\n",
        "#     predicted_fruit = FRUIT_TYPES[np.argmax(fruit_pred)]\n",
        "#     fruit_confidence = np.max(fruit_pred)\n",
        "\n",
        "#     predicted_quality = QUALITY_TYPES[np.argmax(quality_pred)]\n",
        "#     quality_confidence = np.max(quality_pred)\n",
        "\n",
        "#     # Create explanatory text\n",
        "#     explanation = (\n",
        "#         f\"Prediction for the image:\\n\"\n",
        "#         f\"- Predicted Fruit: {predicted_fruit} (Confidence: {fruit_confidence:.2f})\\n\"\n",
        "#         f\"- Predicted Quality: {predicted_quality} (Confidence: {quality_confidence:.2f})\\n\\n\"\n",
        "#         f\"Insights:\\n\"\n",
        "#         f\"- The model is highly confident in the fruit prediction if the confidence is above 0.7.\\n\"\n",
        "#         f\"- Quality prediction confidence helps in understanding the ripeness and edibility of the fruit. \\n\"\n",
        "#         f\"- The Grad-CAM heatmap indicates the areas of the image that were most influential in making the predictions.\"\n",
        "#     )\n",
        "\n",
        "#     return {\n",
        "#         'fruit_type': predicted_fruit,\n",
        "#         'fruit_confidence': fruit_confidence,\n",
        "#         'quality': predicted_quality,\n",
        "#         'quality_confidence': quality_confidence,\n",
        "#         'explanation': explanation,\n",
        "#         'original_image_path': original_image_path,\n",
        "#         'heatmap_path': heatmap_path,\n",
        "#         'overlay_path': overlay_path\n",
        "#     }"
      ],
      "metadata": {
        "id": "k3x8C63D43lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prediction\n",
        "test_image_path = '/content/sample_images/IMG202007281550021.jpg'  # Replace with actual test image path\n",
        "predictions = explain_prediction(model, test_image_path)\n",
        "\n",
        "print(\"Predictions:\")\n",
        "print(f\"Fruit Type: {predictions['fruit_type']} (Confidence: {predictions['fruit_confidence'] * 100:.2f}%)\")\n",
        "print(f\"Quality: {predictions['quality']} (Confidence: {predictions['quality_confidence'] * 100:.2f}%)\")"
      ],
      "metadata": {
        "id": "Wa7VL34e3Ber"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compute Backend** - actual"
      ],
      "metadata": {
        "id": "Fr4ODIh2_zn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --ignore-installed tensorflow==2.17.0 flask pyngrok jinja2 pymongo Flask-PyMongo\n",
        "# --ignore-installed"
      ],
      "metadata": {
        "id": "W1Ukw25TBrQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "rG79cEXRzvWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import h5py\n",
        "import numpy as np\n",
        "# Define your model repository and file name\n",
        "repo_name = \"spectrewolf8/MobileNetv3_fruit_quality_classifier\"\n",
        "filename = \"MobileNetv3_fruit_quality_classifier.h5\"  # Update this to the actual model file name\n",
        "\n",
        "# Define the directory where you want to save the downloaded model\n",
        "download_dir = \"/content/drive/MyDrive/#shaham_com_1_fruits_classifier_v2-backend_storage/model/\"\n",
        "\n",
        "# Download the model file from Hugging Face Hub to the specified directory\n",
        "local_model_path = hf_hub_download(repo_id=repo_name, filename=filename, cache_dir=download_dir)\n",
        "\n",
        "def load_model_with_custom_objects():\n",
        "    custom_objects = {\n",
        "        'Functional': tf.keras.Model,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # First attempt: direct loading\n",
        "        model = tf.keras.models.load_model(local_model_path, custom_objects=custom_objects)\n",
        "        return model\n",
        "    except (ValueError, TypeError) as e:\n",
        "        print(f\"Standard loading failed. Attempting alternative loading method. Error: {str(e)}\")\n",
        "\n",
        "        # Second attempt: manual reconstruction\n",
        "        try:\n",
        "            with h5py.File(local_model_path, 'r') as f:\n",
        "                model_config = f.attrs.get('model_config')\n",
        "                if model_config is None:\n",
        "                    raise ValueError(\"No model configuration found in the H5 file\")\n",
        "\n",
        "                # Decode model config if it's in bytes\n",
        "                if isinstance(model_config, bytes):\n",
        "                    model_config = model_config.decode('utf-8')\n",
        "\n",
        "                # Parse the config\n",
        "                model_config = json.loads(model_config)\n",
        "\n",
        "                # Create the model from config\n",
        "                model = tf.keras.models.model_from_json(json.dumps(model_config), custom_objects=custom_objects)\n",
        "\n",
        "                # Load weights manually\n",
        "                weight_names = [name for name in f.keys() if 'layer' in name]\n",
        "                for name in weight_names:\n",
        "                    g = f[name]\n",
        "                    weights = [np.array(g[wname]) for wname in g.keys()]\n",
        "                    model.get_layer(name).set_weights(weights)\n",
        "\n",
        "                return model\n",
        "        except Exception as e:\n",
        "            print(f\"Alternative loading method failed. Error: {str(e)}\")\n",
        "\n",
        "            # Third attempt: try loading as SavedModel format\n",
        "            try:\n",
        "                model = tf.keras.models.load_model(local_model_path, custom_objects=custom_objects)\n",
        "                return model\n",
        "            except Exception as e:\n",
        "                print(f\"All loading attempts failed. Final error: {str(e)}\")\n",
        "                raise\n",
        "\n",
        "# Usage\n",
        "try:\n",
        "    model = load_model_with_custom_objects()\n",
        "    print(\"Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load model: {str(e)}\")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2XUf0D_6la49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "FRUIT_TYPES = ['Apple', 'Banana', 'Guava', 'Lime', 'Orange', 'Pomegranate']\n",
        "QUALITY_TYPES = ['Good', 'Bad']\n",
        "\n",
        "def generate_gradcam(model, image, layer_name, class_idx=None):\n",
        "    \"\"\"\n",
        "    Generate Grad-CAM heatmap for the specified layer and class index.\n",
        "\n",
        "    Args:\n",
        "        model: Trained TensorFlow model\n",
        "        image: Preprocessed input image (normalized, expanded dims)\n",
        "        layer_name: Name of the target convolutional layer\n",
        "        class_idx: Index of the target class (None for multi-output models)\n",
        "\n",
        "    Returns:\n",
        "        Normalized heatmap\n",
        "    \"\"\"\n",
        "    # Get the target layer\n",
        "    grad_model = Model(\n",
        "        inputs=[model.inputs],\n",
        "        outputs=[model.get_layer(layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_output, predictions = grad_model(image)\n",
        "        if isinstance(predictions, list):\n",
        "            # For multi-output model, sum up the outputs\n",
        "            loss = sum(tf.reduce_sum(pred) for pred in predictions)\n",
        "        else:\n",
        "            if class_idx is None:\n",
        "                loss = tf.reduce_sum(predictions)\n",
        "            else:\n",
        "                loss = predictions[:, class_idx]\n",
        "\n",
        "    # Calculate gradients\n",
        "    grads = tape.gradient(loss, conv_output)\n",
        "\n",
        "    # Global average pooling\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Weight the channels by corresponding gradients\n",
        "    conv_output = conv_output[0]\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
        "\n",
        "    # ReLU\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
        "\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def process_and_overlay_heatmap(image_path, heatmap, target_size=(IMG_SIZE, IMG_SIZE)):\n",
        "    \"\"\"\n",
        "    Process the heatmap and overlay it on the original image.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the original image\n",
        "        heatmap: Generated heatmap\n",
        "        target_size: Size to resize the heatmap and image\n",
        "\n",
        "    Returns:\n",
        "        original_img: Resized original image\n",
        "        processed_heatmap: Processed heatmap image\n",
        "        overlaid_img: Heatmap overlaid on original image\n",
        "    \"\"\"\n",
        "    # Load and resize original image\n",
        "    original_img = cv2.imread(image_path)\n",
        "    original_img = cv2.resize(original_img, target_size)\n",
        "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process heatmap\n",
        "    heatmap = cv2.resize(heatmap, target_size)\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    processed_heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    processed_heatmap = cv2.cvtColor(processed_heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Overlay heatmap on original image\n",
        "    overlaid_img = cv2.addWeighted(original_img, 0.7, processed_heatmap, 0.3, 0)\n",
        "\n",
        "    return original_img, processed_heatmap, overlaid_img\n",
        "\n",
        "def calculate_shap_values(model, image_array, background_images=None, num_samples=100):\n",
        "\n",
        "    # Ensure we have the correct image dimensions\n",
        "    if len(image_array.shape) == 3:\n",
        "        image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    # Create background if not provided\n",
        "    if background_images is None:\n",
        "        background_images = np.zeros((1,) + image_array.shape[1:])\n",
        "\n",
        "    # Create separate models for each output\n",
        "    fruit_model = Model(inputs=model.input, outputs=model.outputs[0])\n",
        "    quality_model = Model(inputs=model.input, outputs=model.outputs[1])\n",
        "\n",
        "    # Create GradientExplainer for each output\n",
        "    fruit_explainer = shap.GradientExplainer(fruit_model, background_images)\n",
        "    quality_explainer = shap.GradientExplainer(quality_model, background_images)\n",
        "\n",
        "    # Calculate SHAP values\n",
        "    fruit_shap_values = fruit_explainer.shap_values(image_array, nsamples=num_samples)\n",
        "    quality_shap_values = quality_explainer.shap_values(image_array, nsamples=num_samples)\n",
        "\n",
        "    # Handle different shapes of SHAP values\n",
        "    if isinstance(fruit_shap_values, list):\n",
        "        fruit_shap_values = [np.array(v) for v in fruit_shap_values]\n",
        "    if isinstance(quality_shap_values, list):\n",
        "        quality_shap_values = [np.array(v) for v in quality_shap_values]\n",
        "\n",
        "    return {\n",
        "        'fruit_shap_values': fruit_shap_values,\n",
        "        'quality_shap_values': quality_shap_values\n",
        "    }\n",
        "\n",
        "def save_shap_visualization(shap_values, image_array, save_path):\n",
        "    \"\"\"\n",
        "    Create and save SHAP visualization for 5D SHAP values.\n",
        "\n",
        "    Args:\n",
        "        shap_values: SHAP values with shape (batch, height, width, channels, num_classes)\n",
        "        image_array: Original image array\n",
        "        save_path: Path to save the visualization\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Remove the batch dimension and sum across classes\n",
        "    shap_values_reshaped = np.sum(shap_values[0], axis=-1)  # Now shape is (height, width, channels)\n",
        "\n",
        "    # Create the visualization\n",
        "    shap.image_plot([shap_values_reshaped], image_array[0], show=False)\n",
        "\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def explain_prediction_vbackend(model, image_path, result_dir, target_layer='Conv_1'):\n",
        "    \"\"\"\n",
        "    Generate and save explanation visualizations including SHAP values for the model's prediction.\n",
        "    \"\"\"\n",
        "    # Existing setup code remains the same\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    # Make predictions\n",
        "    fruit_pred, quality_pred = model.predict(img_array)\n",
        "\n",
        "    # Calculate SHAP values\n",
        "    shap_results = calculate_shap_values(model, img_array)\n",
        "\n",
        "    # Add this after calculating shap_results\n",
        "    print(\"Fruit SHAP values type:\", type(shap_results['fruit_shap_values']))\n",
        "    if isinstance(shap_results['fruit_shap_values'], list):\n",
        "        print(\"Fruit SHAP values shapes:\", [v.shape for v in shap_results['fruit_shap_values']])\n",
        "    else:\n",
        "        print(\"Fruit SHAP values shape:\", shap_results['fruit_shap_values'].shape)\n",
        "\n",
        "    print(\"Quality SHAP values type:\", type(shap_results['quality_shap_values']))\n",
        "    if isinstance(shap_results['quality_shap_values'], list):\n",
        "        print(\"Quality SHAP values shapes:\", [v.shape for v in shap_results['quality_shap_values']])\n",
        "    else:\n",
        "        print(\"Quality SHAP values shape:\", shap_results['quality_shap_values'].shape)\n",
        "\n",
        "    # Add debugging information\n",
        "    print(\"Fruit SHAP values shape:\", shap_results['fruit_shap_values'].shape)\n",
        "    print(\"Quality SHAP values shape:\", shap_results['quality_shap_values'].shape)\n",
        "\n",
        "    # Generate Grad-CAM heatmap\n",
        "    heatmap = generate_gradcam(model, img_array, target_layer)\n",
        "    original_img, heatmap_img, overlay_img = process_and_overlay_heatmap(image_path, heatmap)\n",
        "\n",
        "    # Save images\n",
        "    file_paths = {}\n",
        "    for img_type, img_data in [\n",
        "        ('original', original_img),\n",
        "        ('heatmap', heatmap_img),\n",
        "        ('overlay', overlay_img)\n",
        "    ]:\n",
        "        save_path = os.path.join(result_dir, f'{img_type}_image.jpg')\n",
        "        plt.imsave(save_path, img_data)\n",
        "        file_paths[f'{img_type}_path'] = f'/static/results/{img_type}_image.jpg'\n",
        "\n",
        "    try:\n",
        "        # Save SHAP visualizations for each output\n",
        "        fruit_shap_path = os.path.join(result_dir, 'fruit_shap.jpg')\n",
        "        save_shap_visualization(shap_results['fruit_shap_values'], img_array, fruit_shap_path)\n",
        "        file_paths['fruit_shap_path'] = f'/static/results/fruit_shap.jpg'\n",
        "\n",
        "        quality_shap_path = os.path.join(result_dir, 'quality_shap.jpg')\n",
        "        save_shap_visualization(shap_results['quality_shap_values'], img_array, quality_shap_path)\n",
        "        file_paths['quality_shap_path'] = f'/static/results/quality_shap.jpg'\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating SHAP visualizations: {str(e)}\")\n",
        "        # If SHAP visualization fails, we still want to return other results\n",
        "\n",
        "    # Rest of your function remains the same\n",
        "    predicted_fruit = FRUIT_TYPES[np.argmax(fruit_pred)]\n",
        "    fruit_confidence = float(np.max(fruit_pred))\n",
        "    predicted_quality = QUALITY_TYPES[np.argmax(quality_pred)]\n",
        "    quality_confidence = float(np.max(quality_pred))\n",
        "\n",
        "    # Enhanced explanation with SHAP information\n",
        "    explanation = (\n",
        "        f\"Prediction Results:\\n\"\n",
        "        f\"- Fruit: {predicted_fruit} (Confidence: {fruit_confidence:.1%})\\n\"\n",
        "        f\"- Quality: {predicted_quality} (Confidence: {quality_confidence:.1%})\\n\\n\"\n",
        "        f\"Visualization Guide:\\n\"\n",
        "        f\"1. Grad-CAM Heatmap:\\n\"\n",
        "        f\"   - Highlights regions most important for the model's decision\\n\"\n",
        "        f\"   - Brighter colors (red/yellow) indicate higher importance\\n\"\n",
        "        f\"   - Some Images might not have a Grad-Cam, try changing angles and conditions in that case\\n\\n\"\n",
        "        f\"2. SHAP Values:\\n\"\n",
        "        f\"   - Shows pixel-level contributions to the prediction\\n\"\n",
        "        f\"   - Red indicates positive impact, blue indicates negative impact\\n\"\n",
        "        f\"   - Separate visualizations for fruit type and quality predictions\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'fruit_type': predicted_fruit,\n",
        "        'fruit_confidence': f\"{fruit_confidence:.1%}\",\n",
        "        'quality': predicted_quality,\n",
        "        'quality_confidence': f\"{quality_confidence:.1%}\",\n",
        "        'explanation': explanation,\n",
        "        **file_paths\n",
        "    }"
      ],
      "metadata": {
        "id": "c9WSdP9_2GWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "from flask import Flask, request, jsonify, render_template, redirect, url_for, flash, session\n",
        "from flask_pymongo import PyMongo\n",
        "from werkzeug.security import generate_password_hash, check_password_hash\n",
        "from werkzeug.utils import secure_filename\n",
        "from pyngrok import ngrok, conf\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime\n",
        "import getpass\n",
        "from google.colab import userdata\n",
        "import sys\n",
        "\n",
        "# Set the current working directory to where your template files are located\n",
        "project_dir = '/content/drive/MyDrive/#shaham_com_1_fruits_classifier_v2-backend_storage'\n",
        "os.chdir(project_dir)\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "# Flush prints immediately\n",
        "def print_flush(*args, **kwargs):\n",
        "    print(*args, **kwargs)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "# Your NGROK_TOKEN should be set securely in Colab\n",
        "NGROK_TOKEN = userdata.get('NGROK_TOKEN')\n",
        "MONGODB_ATLAS_TOKEN = userdata.get('MONGODB_ATLAS_URI')\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n",
        "UPLOAD_FOLDER = '/content/drive/MyDrive/#shaham_com_1_fruits_classifier_v2-backend_storage/static/uploads'\n",
        "RESULT_FOLDER = '/content/drive/MyDrive/#shaham_com_1_fruits_classifier_v2-backend_storage/static/results'\n",
        "\n",
        "# Function to create directories if they don't exist\n",
        "if not os.path.exists(UPLOAD_FOLDER):\n",
        "    os.makedirs(UPLOAD_FOLDER)\n",
        "\n",
        "if not os.path.exists(RESULT_FOLDER):\n",
        "    os.makedirs(RESULT_FOLDER)\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config['SECRET_KEY'] = '@123'  # Change this to a secure secret key\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "app.config['RESULT_FOLDER'] = RESULT_FOLDER\n",
        "app.config['MONGO_URI'] = f'{MONGODB_ATLAS_TOKEN}/fruits_classifier_v2_users_db'  # Replace with your MongoDB Atlas connection string\n",
        "\n",
        "# print(app.config['MONGO_URI'])\n",
        "\n",
        "# Initialize MongoDB\n",
        "mongo = PyMongo(app)\n",
        "\n",
        "# Helper function to check allowed files\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "# Define your routes (as before)\n",
        "@app.route('/')\n",
        "def index():\n",
        "    if 'username' in session:\n",
        "        return render_template('submission.html', username=session['username'])\n",
        "    return render_template('login.html')\n",
        "\n",
        "@app.route('/register', methods=['GET', 'POST'])\n",
        "def register():\n",
        "    if request.method == 'POST':\n",
        "        users = mongo.db.users\n",
        "        existing_user = users.find_one({'username': request.form['username']})\n",
        "\n",
        "        if existing_user is None:\n",
        "            hashpass = generate_password_hash(request.form['password'])\n",
        "            users.insert_one({\n",
        "                'username': request.form['username'],\n",
        "                'password': hashpass\n",
        "            })\n",
        "            session['username'] = request.form['username']\n",
        "            return redirect(url_for('submission'))\n",
        "\n",
        "        flash('Username already exists!')\n",
        "    return render_template('register.html')\n",
        "\n",
        "@app.route('/login', methods=['GET', 'POST'])\n",
        "def login():\n",
        "    if request.method == 'POST':\n",
        "        users = mongo.db.users\n",
        "        login_user = users.find_one({'username': request.form['username']})\n",
        "\n",
        "        if login_user:\n",
        "            if check_password_hash(login_user['password'], request.form['password']):\n",
        "                session['username'] = request.form['username']\n",
        "                return redirect(url_for('submission'))\n",
        "\n",
        "        flash('Invalid username/password combination')\n",
        "    return render_template('login.html')\n",
        "\n",
        "@app.route('/logout')\n",
        "def logout():\n",
        "    session.pop('username', None)\n",
        "    return redirect(url_for('index'))\n",
        "\n",
        "@app.route('/submission', methods=['GET', 'POST'])\n",
        "def submission():\n",
        "    if 'username' not in session:\n",
        "        return redirect(url_for('login'))\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        if 'file' not in request.files:\n",
        "            flash('No file part!')\n",
        "            return redirect(request.url)\n",
        "\n",
        "        file = request.files['file']\n",
        "        if file.filename == '':\n",
        "            flash('No selected file!')\n",
        "            return redirect(request.url)\n",
        "\n",
        "        if file and allowed_file(file.filename):\n",
        "            filename = secure_filename(file.filename)\n",
        "            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "            file.save(filepath)\n",
        "\n",
        "            # Store the filename in the session so it can be used in the results page\n",
        "            session['uploaded_file_path'] = filepath\n",
        "\n",
        "            return redirect(url_for('results'))\n",
        "\n",
        "        flash('Invalid file type!')\n",
        "        return redirect(request.url)\n",
        "\n",
        "    return render_template('submission.html', username=session['username'])\n",
        "\n",
        "@app.route('/results')\n",
        "def results():\n",
        "    if 'username' not in session:\n",
        "        return redirect(url_for('login'))\n",
        "\n",
        "    if 'uploaded_file_path' not in session:\n",
        "        flash('No file uploaded!')\n",
        "        return redirect(url_for('submission'))\n",
        "\n",
        "    filepath = session['uploaded_file_path']\n",
        "\n",
        "    # Run your model prediction\n",
        "    result = explain_prediction_vbackend(model, filepath, app.config['RESULT_FOLDER'])\n",
        "\n",
        "    # Ensure proper type conversion for confidence values\n",
        "    try:\n",
        "        result['fruit_confidence'] = float(result['fruit_confidence'])\n",
        "        result['quality_confidence'] = float(result['quality_confidence'])\n",
        "    except (ValueError, TypeError):\n",
        "        # If conversion fails, ensure they're strings\n",
        "        result['fruit_confidence'] = str(result['fruit_confidence'])\n",
        "        result['quality_confidence'] = str(result['quality_confidence'])\n",
        "        result['timestamp'] = datetime.datetime.utcnow()\n",
        "    # Save the results to the MongoDB database\n",
        "    mongo.db.predictions.insert_one({\n",
        "        'username': session['username'],\n",
        "        'filename': os.path.basename(filepath),\n",
        "        'fruit_type': result['fruit_type'],\n",
        "        'fruit_confidence': result['fruit_confidence'],\n",
        "        'quality': result['quality'],\n",
        "        'quality_confidence': result['quality_confidence'],\n",
        "        'timestamp': datetime.datetime.utcnow()\n",
        "    })\n",
        "\n",
        "    return render_template('results.html', result=result)\n",
        "\n",
        "\n",
        "# Function to start ngrok in a thread\n",
        "def start_ngrok():\n",
        "    conf.get_default().auth_token = NGROK_TOKEN\n",
        "    port = 5000\n",
        "    public_url = ngrok.connect(port)\n",
        "    print_flush(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"\")\n",
        "\n",
        "# Start ngrok in a new thread\n",
        "threading.Thread(target=start_ngrok).start()\n",
        "\n",
        "# Run Flask app normally (main thread)\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, use_reloader=False)\n"
      ],
      "metadata": {
        "id": "nZI6brg5Hn37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CLI/CMDS** - dispensable"
      ],
      "metadata": {
        "id": "idGhdwU4_3I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/sample_images"
      ],
      "metadata": {
        "id": "PHXcXz6N3XFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd_dir = '/content/drive/MyDrive/#shaham_com_1_fruits_classifier_v2-backend_storage'"
      ],
      "metadata": {
        "id": "rC90EMOM7mfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "n06LkC_jdHhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/static/uploads'"
      ],
      "metadata": {
        "id": "6mj0nK1ccxP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/sample_images/ /content/drive/MyDrive/#shaham_com_1_fruits_classifier_v2-backend_storage/"
      ],
      "metadata": {
        "id": "3Vtpod8w-Ld_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/static/"
      ],
      "metadata": {
        "id": "ViEdGnXJ_kXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $dir"
      ],
      "metadata": {
        "id": "o8p_gGcb_vNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > '/content/drive/MyDrive/#shaham_com_1_fruits_classifier_v2-backend_storage/requirements.txt'"
      ],
      "metadata": {
        "id": "Xx9bB9LQAByy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6InuGlq90tsd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}